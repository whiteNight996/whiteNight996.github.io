<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hadoop分布式文件系统]]></title>
    <url>%2F2019%2F09%2F20%2FHadoop%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[1.Hadoop分布式文件系统1.1 HDFS的设计 HDFS以流式数据访问模式来存储超大文件。 流式数据访问：一次写入、多次读取 不适合低时间延迟的数据访问。HDFS是为高数据吞吐量应用优化的，可能会牺牲时间延迟。 不适合大量的小文件。由于namenode 将文件系统的元数据存储到内存中，因此namenode的内存容量决定了此文件系统所能存储的文件总数。 不适合多用户写入，任意修改文件的场景。HDFS的文件写入只支持单个写入，而且写操作都是”只添加”的方式写在文件末尾。 1.2 HDFS的概念数据块HDFS中块大小默认128MB，HDFS中小于一个块大小的文件不会占据整个块的空间。 HDFS的块比磁盘的块大，其目的是为了最小化寻址开销。一般寻址时间占传输时间的1%。 NameNode和DataNode1）HDFS集群中有两类节点以管理节点-工作节点模式运行，即一个NameNode和多个DataNode。 ①NameNode管理文件系统的命名空间，以两个文件永久形式保存在本地磁盘上：Edits日志文件和FsImage镜像文件；②NameNode记录每个文件中各个块所在的数据节点信息，但它不会永久保存块的位置信息，因为这些信息会在系统启动时根据数据节点信息重建。 DataNode会根据需要存储并检索数据块，并且定期向NameNode发送他们所存储的块列表。 2）NameNode容错机制（两种） 备份那些组成文件系统元数据持久状态的文件。Hadoop可以配置NameNode在多个文件系统上保存元数据的持久状态。一般的配置是，将持久状态写入本地磁盘的同时，写入一个NFS。 运行SecondaryNameNode，但它不能被用作NameNode。SecondaryNameNode作用就是定期合并编辑日志与命名空间镜像。以防止编辑日志过大。 块缓存通常DataNode从磁盘中读取块，但对于访问频繁的文件，其对应的块可能被显式的缓存在DataNode的内存中，以堆外缓存的形式存在。 联邦HDFSNameNode在内存中保存文件系统中的每个文件和每个数据块的引用关系，这就意味着，内存将成为系统横向扩展的瓶颈。在2.x发行版本中允许系统通过添加NameNode来实现扩展，其中每个NameNode管理文件系统命名空间的一部分。 在联邦环境下，每个NameNode维护一个命名空间卷（namespace volume），由命名空间的元数据和一个数据块池（block pool）组成，数据块池包含该命名空间下文件的所有数据块。 HDFS的高可用性通过联邦HDFS和SecondaryNameNode能防止数据丢失，但是依旧无法实现文件系统的高可用性。NameNode依然存在单点失效（SPOF）问题，一旦NameNode失效，Hadoop系统无法提供服务直到有新的NameNode上线。 Hadoop2增加了HDFS高可用的支持，配置了Active-Standby NameNode，当活动NameNode失效，备用NameNode就会接管它的任务并开始服务，但需要在架构上做些修改： NameNode之间需要共享编辑日志，实现与活动NameNode的状态同步。 DataNode需要同时向两个NameNode发送数据处理报告。 辅助NameNode的角色被备用NameNode所包含，备用NameNode为活动的NameNode命名空间设置周期性检查点。 故障切换故障转移控制器（failover controller）管理将活动NameNode转移为备用NameNode的转移过程。有多种故障转移器。默认使用ZooKeeper来确保有且只有一个活动的NameNode，起哄做就是监视宿主NameNode是否失效（心跳机制）并在失效时进行故障切换。 1.3 Hadoop文件系统Hadoop有一个抽象的文件系统，HDFS只是其中的一个实现。org.apache.hadoop.hdfs.DistributedFileSystem 从Hadoop URL读取数据最简单的方法就是使用java.net.URL对象打开数据流，从中读取数据 1234567InputStream in = null;try&#123; in = new URL("hdfs://host/path").openStream(); IOUtils.copyBytes(in,System.out,4096,false);//流的对拷，4096-用于复制的缓冲区大小，false-复制结束后是否关闭数据流&#125;finally&#123; IOUtils.closeStream(in); //关闭数据流&#125; 通过FileSystem API读取数据Hadoop文件系统中通过Hadoop Path对象来代表文件，可以将路径视为一个Hadoop URI。 123public static FileSystem get(Configuration conf)public static FileSystem get(URI uri,Configuration conf)public static FileSystem get(URI uri,Configuration conf,String user) 有些情况，你可能需要获取本地文件系统的运行实例： 1public static LocalFileSystem getLocal(Configuration conf) 有了FileSystem实例，可以调用open函数来获取文件的输入流. 12public FSDataInputStream open(Path f) //默认使用缓冲区大小为4KBpublic abstract FSDataInputStream open(Path f,int bufferSize) 示例代码 1234567891011121314public class FileSystemCat&#123; public static void main(String[] args) throw Exception&#123; String uri = args[0]; Configuration conf = new Configuration(); FileSystem fs = FileSystem.get(URI.create(uri),conf); InputStream in = null; try&#123; in = fs.open(new Path(uri)); IOUtils.copyBytes(in,System.out,4096,false); &#125;finally&#123; IOUtils.closeStream(in); //关闭数据流 &#125; &#125;&#125; FSDataInputStreamFSDataInputStream是继承了java.io.DataInputStream，并支持随机访问，可以从流的任意位置读取数据 12345package org.apache.ahdoop.fs;public class FSDataInputStream extends DataInputStream implements Seekable,PositionReadable&#123; //...&#125; Seekable接口支持在文件中找到指定位置，并提供一个查询当前位置相对于文件起始位置偏移量（getPos()）的查询方法。 1.4 数据流文件读取 这个设计的一个重点是，客户端可以直接连接到DataNode检索数据，且NameNode告诉客户端每个块所在的最佳DataNode。 NameNode只需要响应块位置的请求（这些信息存储在内存中，非常高效），无需响应数据请求，不会因为客户端数量的增长使得NameNode成为瓶颈。 网络拓扑与Hadoop在海量数据处理中，其主要限制因素是节点之间数据的传输速率-网络带宽。如何衡量节点之间的带宽？ 节点距离：两个节点到达最近的共同祖先的距离总和。 distance(/d1/r1/n1,/d1/r1/n1) = 0 （同一节点上的进程） distance(/d1/r1/n1,/d1/r1/n2) = 2 （同一机架上的不同节点） distance(/d1/r1/n1,/d1/r2/n1) = 4 （同一数据中心不同机架上的节点） distance(/d1/r1/n1,/d2/r3/n4) = 6 （不同数据中心的节点） 机架感知（副本存储节点选择）1For the common case, when the replication factor is three, HDFS’s placement policy is to put one replica on one node in the local rack, another on a different node in the local rack, and the last on a different node in a different rack. 第一个副本在client所处的节点上，如果客户端在集群外，随机选一个； 第二个副本和第一个副本位于相同机架，随机节点； 第三个副本位于不同机架，随机节点。 文件写入]]></content>
  </entry>
  <entry>
    <title><![CDATA[Shell-重定向]]></title>
    <url>%2F2019%2F08%2F02%2FShell-%E9%87%8D%E5%AE%9A%E5%90%91%2F</url>
    <content type="text"><![CDATA[Shell输入输出重定向解析： 1nohup ./hiveserver2 &gt; /opt/module/hive/logs/server.log 2&gt;&amp;1 &amp; nohub和&amp;区别信号，是Unix系统中进程间通信的一种异步通信机制。 （1）SIGINT信号 （2）SIGHUB信号 Ctrl + C 产生SIGINT信号，关闭shell产生SIGHUB信号 &amp;：命令后面加一个“&amp;”，表示后台运行 &amp;只对SIGINT信号免疫，对SIGHUB信号不免疫 也就是说，&amp;在你使用Ctrl + C 关闭时，进程依然存活；但如果你把shell窗口关闭，进程就会被杀死。 nohub：忽略SIGHUB信号 单独使用nohub时，关闭窗口不会影响进程，但是Ctrl +C 操作会使得进程停止（对SIGHUB免疫，但是对SIGINT不免疫）。 总结要想使进程不受shell窗口关闭 和 Ctrl + C操作的影响，可以将nohup和&amp;指令一起使用。 1nohub ./xxx脚本 ... &amp; 重定向列表 命令 说明 command &gt; file 将输出重定向到 file command &lt; file 将输入重定向到 file command &gt;&gt; file 将输出以追加的方式重定向到 file n &gt; file 将文件描述符为 n 的文件重定向到 file n &gt;&gt; file 将文件描述符为 n 的文件以追加的方式重定向到 file n &gt;&amp; m 将输出文件 m 和 n 合并 n &lt;&amp; m 将输入文件 m 和 n 合并 重定向深入理解一般情况下，每个Unix和Linux命令运行时都会打开三个文件： 标准输入文件(stdin)：stdin的文件描述符为0，Unix程序默认从stdin读取数据。 标准输出文件(stdout)：stdout 的文件描述符为1，Unix程序默认向stdout输出数据。 标准错误文件(stderr)：stderr的文件描述符为2，Unix程序会向stderr流中写入错误信息 默认情况下，command &gt; file 将 stdout 重定向到 file，command &lt; file 将stdin 重定向到 file。 如果希望 stderr 重定向到 file，可以这样写： 1$ command 2 &gt; file 2 表示标准错误文件(stderr)。 如果希望将 stdout 和 stderr 合并后重定向到 file，可以这样写： 12345$ command &gt; file 2&gt;&amp;1或者$ command &gt;&gt; file 2&gt;&amp;1 Linux xargs命令xargs 是给命令传递参数的一个过滤器，也是组合多个命令的一个工具。 xargs 可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据。 1somecommand |xargs -选项 command xargs 结合 find 使用 用 rm 删除太多的文件时候，可能得到一个错误信息：/bin/rm Argument list too long. 用 xargs 去避免这个问题： 1find . -type f -name "*.log" -print0 | xargs -0 rm -f]]></content>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK1.8源码-ArrayList]]></title>
    <url>%2F2019%2F08%2F01%2FJDK1.8%E6%BA%90%E7%A0%81-ArrayList%2F</url>
    <content type="text"><![CDATA[ArrayList 源码解析（1）JDK1.8：new ArrayList()：发现内部初始化为了一个长度为0的空数组 DEFAULTCAPACITY_EMPTY_ELEMENTDATA ​ JDK1.7版本：也是初始化为长度为0的空数组 EMPTY_ELEMENTDATA; ​ JDK1.6版本：初始化为长度为10的数组 为什么要初始化为空数组呢？ 因为开发中，很多时候创建了ArrayList的对象，但是没有装元素，这个时候的话，如果初始化为10的数组，就浪费空间了。 （2）什么时候扩容？– add(Object e） JDK1.8：第一次添加元素，扩容为长度为10的数组；如果不够了，再扩容为1.5倍 源码1234567891011121314151617181920212223242526272829303132333435363738394041424344private static final int DEFAULT_CAPACITY = 10;private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;//初始化为空数组&#125;public boolean add(E e) &#123; //查看当前数组是否够多存一个元素 ensureCapacityInternal(size + 1); // Increments modCount!! //存入新元素到[size]位置，然后size自增1 elementData[size++] = e; return true;&#125;private void ensureCapacityInternal(int minCapacity) &#123; //如果当前数组还是空数组 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; //那么minCapacity取DEFAULT_CAPACITY与minCapacity的最大值 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; //查看是否需要扩容 ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++;//修改次数加1 // 如果需要的最小容量 比 当前数组的长度 大，即当前数组不够存，就扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125; private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length;//当前数组容量 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);//新数组容量是旧数组容量的1.5倍 //看旧数组的1.5倍是否够 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //看旧数组的1.5倍是否超过最大数组限制 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); //复制一个新数组 elementData = Arrays.copyOf(elementData, newCapacity); &#125; 1234567891011121314151617181920public E remove(int index) &#123; rangeCheck(index);//检验index是否合法 modCount++;//修改次数加1 //取出[index]位置的元素，[index]位置的元素就是要被删除的元素，用于最后返回被删除的元素 E oldValue = elementData(index); //需要移动的元素个数 int numMoved = size - index - 1; //如果需要移动元素，就用System.arraycopy移动元素 if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); //将elementData[size-1]位置置空，让GC回收空间，元素个数减少 elementData[--size] = null; // clear to let GC do its work return oldValue;&#125; 12345678910111213 public E set(int index, E element) &#123; rangeCheck(index);//检验index是否合法 //取出[index]位置的元素，[index]位置的元素就是要被替换的元素，用于最后返回被替换的元素 E oldValue = elementData(index); //用element替换[index]位置的元素 elementData[index] = element; return oldValue;&#125;public E get(int index) &#123; rangeCheck(index);//检验index是否合法 return elementData(index);//返回[index]位置的元素&#125; 12345678910111213141516171819202122232425262728public int indexOf(Object o) &#123; //分为o是否为空两种情况 if (o == null) &#123; //从前往后找 for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1;&#125;public int lastIndexOf(Object o) &#123; //分为o是否为空两种情况 if (o == null) &#123; //从后往前找 for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1;&#125;]]></content>
      <categories>
        <category>Java内功心法</category>
      </categories>
      <tags>
        <tag>JDK源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F07%2F25%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
